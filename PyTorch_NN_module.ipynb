{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMrhlOOvf/RlfPKbSqUSCRW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Namesakenberg/Practical_deep_learning_using_pytorch/blob/main/PyTorch_NN_module.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NN Module in pytorch\n",
        "\n",
        "> torch.nn module is a library which helps us in making neural networks easily it offers pre-built layers, loss functions , and other utilities.\n",
        "\n",
        "> it provides us layers , activations , loss functions , regularizations and dropouts\n"
      ],
      "metadata": {
        "id": "FAVrkStU8jCo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a single neural network using the nn module and the optim module of pytorch\n",
        "# in the previous made neron the update in the values of the weights and bias was done manually\n",
        "# in the below code the updating of the weights and the bias terms are done using the optim module in pytorch"
      ],
      "metadata": {
        "id": "cPwOn88tSxZq"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "PIklwYxQ90q2"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class mymodel(nn.Module):                          # make class with parent class as nn.Module\n",
        "  def __init__(self,num_features) -> None:\n",
        "    super().__init__()\n",
        "    self.linear = nn.Linear(num_features , 1)        # nn.linear module calculates the weighted sum\n",
        "    self.sigmoid=nn.Sigmoid()                        # get the activation\n",
        "    self.loss = nn.BCELoss()                         # get the loss function\n",
        "    self.lr = 0.01                                   # set the learning rate\n",
        "    self.optimizer = torch.optim.SGD(self.parameters() , lr =self.lr)         # set the optimizer,its type and pass the parameters\n",
        "\n",
        "  def forward_pass(self,X):\n",
        "    z = self.linear(X)                      # calculate z\n",
        "    y_pred = self.sigmoid(z)                # make prediction\n",
        "    return y_pred\n",
        "\n",
        "  def backprop(self,X,y_true):\n",
        "    self.optimizer.zero_grad()                 # set the gradients zero befpre pass\n",
        "    y_pred = self.forward_pass(X)      # get prediciton\n",
        "    bce = self.loss(y_pred , y_true)            # pass it into loss function with true prediction\n",
        "    bce.backward()                                # call backpropagation\n",
        "    self.optimizer.step()                         # update the weights and bias terms\n",
        "    return bce.item()       # return loss\n",
        "\n"
      ],
      "metadata": {
        "id": "6fSuW8EpAOCx"
      },
      "execution_count": 16,
      "outputs": []
    }
  ]
}